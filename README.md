# Unsupervised-Learning-Clustering-Dimensionality-Reduction-
## üìö Sobre o Projeto

Este projeto aborda t√©cnicas fundamentais de aprendizado n√£o supervisionado, incluindo clusteriza√ß√£o (K-Means, Hierarchical Clustering) e redu√ß√£o de dimensionalidade (PCA). O foco √© identificar estruturas ocultas nos dados sem o uso de r√≥tulos pr√©vios.

**Objetivo Principal**: Demonstrar como algoritmos n√£o supervisionados podem revelar padr√µes e agrupamentos naturais em dados n√£o rotulados.

## üß© T√©cnicas Implementadas

### üî∑ Clusteriza√ß√£o (Clustering)
- **K-Means**: Agrupamento particional com n√∫mero pr√©-definido de clusters
- **Hierarchical Clustering**: Agrupamento hier√°rquico com dendrogramas
- **DBSCAN**: Detec√ß√£o de clusters de densidade vari√°vel

### üìâ Redu√ß√£o de Dimensionalidade
- **PCA (Principal Component Analysis)**: Redu√ß√£o linear de dimensionalidade
- **An√°lise de Vari√¢ncia**: Interpreta√ß√£o dos componentes principais
- **Visualiza√ß√£o em 2D/3D**: Proje√ß√£o de dados multidimensionais

## üìä Dataset

**Fonte**: `sklearn.datasets.load_iris`

**Caracter√≠sticas**:
- 150 amostras de flores Iris
- 4 features num√©ricas:
  - Comprimento da s√©pala
  - Largura da s√©pala
  - Comprimento da p√©tala

## üìà Resultados e An√°lises
### 1. K-Means Clustering
- Agrupamento eficiente em 3 clusters
- Identifica√ß√£o de padr√µes naturais nos dados
- Visualiza√ß√£o da separa√ß√£o entre esp√©cies

### 2. Hierarchical Clustering
- Dendrograma mostrando estrutura hier√°rquica
- Identifica√ß√£o do n√∫mero ideal de clusters
- Compara√ß√£o com resultados do K-Means

### 3. PCA - An√°lise de Componentes Principais
- Redu√ß√£o de 4D ‚Üí 2D preservando ~95% da vari√¢ncia
- Visualiza√ß√£o eficiente em duas dimens√µes
- Identifica√ß√£o dos componentes mais importantes

## üí° Insights e Aprendizados
### Clusteriza√ß√£o
- K-Means: Eficiente para clusters esf√©ricos e bem separados
- Hierarchical Clustering: Ideal quando a estrutura hier√°rquica √© importante
- Escolha do N√∫mero de Clusters: M√©todo do cotovelo e dendrogramas s√£o cruciais

### Redu√ß√£o de Dimensionalidade
- PCA: Mant√©m a vari√¢ncia global mas pode perder estruturas locais
- Interpretabilidade: Componentes principais podem ter significado f√≠sico
- Visualiza√ß√£o: Ferramenta poderosa para explorar dados multidimensionais

## Aplica√ß√µes Pr√°ticas
- Segmenta√ß√£o de clientes
- Detec√ß√£o de anomalias
- Pr√©-processamento para outros algoritmos
- Visualiza√ß√£o de dados complexos

### üìä Visualiza√ß√µes Inclu√≠das
- Gr√°fico de clusters K-Means
- Dendrograma do clustering hier√°rquico
- Proje√ß√£o PCA 2D/3D
- An√°lise de vari√¢ncia dos componentes
- Compara√ß√£o entre m√©todos de clusteriza√ß√£o

### üîß Metodologia
- **Pr√©-processamento:** Normaliza√ß√£o e escalonamento dos dados
- **Clusteriza√ß√£o:** Aplica√ß√£o de m√∫ltiplos algoritmos
- **Avalia√ß√£o:** An√°lise qualitativa e quantitativa dos clusters
- **Redu√ß√£o de Dimensionalidade:** PCA e interpreta√ß√£o dos componentes
- **Valida√ß√£o:** Compara√ß√£o com r√≥tulos verdadeiros (quando dispon√≠vel)

## üéì Conceitos Te√≥ricos Abordados
### Clusteriza√ß√£o
- Medidas de similaridade e dist√¢ncia
- Algoritmos particionais vs hier√°rquicos
- M√©todos de valida√ß√£o de clusters
- Escolha do n√∫mero √≥timo de clusters

### Redu√ß√£o de Dimensionalidade
- √Ålgebra linear aplicada
- Autovalores e autovetores
- Preserva√ß√£o de vari√¢ncia
- Interpretabilidade de componentes


## üìã Estrutura Detalhada dos Notebooks:
### 01_kmeans_clustering.ipynb
- An√°lise explorat√≥ria do dataset Iris
- Implementa√ß√£o do K-Means
- M√©todo do cotovelo para escolha de K
- Visualiza√ß√£o dos clusters

### 02_hierarchical_clustering.ipynb
- endrogramas e interpreta√ß√£o
- Agglomerative Clustering
- Compara√ß√£o de m√©todos de linkage
- Determina√ß√£o do n√∫mero de clusters

### 03_pca_analysis.ipynb
- An√°lise de componentes principais
- Vari√¢ncia explicada
- Interpreta√ß√£o dos componentes
- Visualiza√ß√£o 2D/3D

### 04_comparative_analysis.ipynb
- Compara√ß√£o entre t√©cnicas
- An√°lise de performance
- Casos de uso para cada m√©todo
